{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # hide warnings\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERVIEW:\n",
    "# Step 1: Relabel the zonenumbers to our actual numbers (such that zone 3 has id 3, not id 7 for example)\n",
    "# Step 2: Split the shapefile into the different zones\n",
    "# Step 3: Clustering + retrieving for each original zone to which cluster it belongs\n",
    "# Step 4: Update the centroids and the OD-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "city = \"BRUSSEL\"\n",
    "radius = \"40\"\n",
    "\n",
    "path_orig_shapefile = f\"STA_prep/shapefile_data/{city}_{radius}_10/{city}_{radius}_10.shp\"\n",
    "qgis_path = f\"QGIS/{city}_V2_{radius}_10.shp\"\n",
    "shapefile = gpd.read_file(path_orig_shapefile)\n",
    "shapefile[\"ZONENUMMER\"] = list(range(1,len(shapefile)+1))\n",
    "shapefile.to_file(qgis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: QGIS\n",
    "# Find centroid of whole area --> Split circle into bands with inner and outer radiuses 0-10, 10-20, 20-40 \n",
    "# For radius 0-10: Vector --> Research tools --> Select by location: Select features from Brussel_40_10 by comparing to radius_0-10 based on intersect\n",
    "#                  Right click Brussel_40_10 layer and export the selected features to a new layer brussel_40_10_0-10\n",
    "# For radius 10-20: Vector --> Research tools --> Select by location: 3 operations:\n",
    "#                       1) \"creating new selection\" from brussel_40_10 intersect with radius 10-20\n",
    "#                       2) \"removing from current selection\" from brussel_40-10 equal with brussel_40_10_0-10 (to make sure that no zones is included in multiple bands)\n",
    "#                       3) Export selected features to brussel_40_10_10-20\n",
    "# For radius 20-40: Vector --> Research tools --> Select by location: 4 operations: \n",
    "#                       1) Select all features (such that some small zones from outside the 40 radius are also included)\n",
    "#                       3) \"Remove from current selection\" from brussel_40-10 equal to brussel_40_10_10-20\n",
    "#                       4) \"Remove from current selection\" from brussel_40-10 equal to brussel_40_10_0-10\n",
    "#                       5) Export selected features to brussel_40_10_20-40\n",
    "\n",
    "\n",
    "# TODO: this code is not error proof... 1 zone was included in both 10-20 and 20-40\n",
    "# I removed it manually. Karls' way of working might be easier to use! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation of 233 zones into 59 clusters.\n",
      "Basic statistics of zone aggregation:\n",
      "count    59.000000\n",
      "mean      3.949153\n",
      "std       2.136899\n",
      "min       1.000000\n",
      "25%       2.000000\n",
      "50%       4.000000\n",
      "75%       5.000000\n",
      "max      11.000000\n",
      "dtype: float64\n",
      "\n",
      "Aggregation of 917 zones into 58 clusters.\n",
      "Basic statistics of zone aggregation:\n",
      "count    58.000000\n",
      "mean     15.810345\n",
      "std      10.320235\n",
      "min       6.000000\n",
      "25%       9.000000\n",
      "50%      13.000000\n",
      "75%      20.500000\n",
      "max      67.000000\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: clustering\n",
    "\n",
    "# settings\n",
    "radius1 = \"0-10\"\n",
    "radius2 = \"10-20\"\n",
    "radius3 = \"20-40\"\n",
    "# groupSize1 = 1 not needed\n",
    "groupSize2 = 4\n",
    "groupSize3 = 16\n",
    "\n",
    "# TODO make code more waterproof (naming of input and outputfile)\n",
    "def aggregate_zones(city = city, radius = radius2, idealNbZonesPerCluster = groupSize2):\n",
    "    '''\n",
    "    original shapefile will change: 'cluster' column containing the cluster to which each zone belongs\n",
    "    new shapefill will be created: shapefile consisting of aggregated zones\n",
    "\n",
    "    Note:\n",
    "    code not waterproof: always looks in folder \"QGIS\"\n",
    "    '''\n",
    "    inputFile = f\"QGIS/{city}_V2_40_10_{radius}.shp\"\n",
    "    outputFile = f\"QGIS/{city}_V2_40_10_{radius}_knn.shp\"\n",
    "    shapefile = gpd.read_file(inputFile)\n",
    "\n",
    "    points = np.array(shapefile.centroid.apply(lambda p: [p.x, p.y]).tolist())\n",
    "\n",
    "    k =  int(np.ceil(len(shapefile) / idealNbZonesPerCluster))  # number of clusters to create\n",
    "    print(f'Aggregation of {len(shapefile)} zones into {k} clusters.')\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(points) \n",
    "\n",
    "    shapefile[\"cluster\"] = kmeans.labels_\n",
    "    aggregated = shapefile.dissolve(by=\"cluster\").reset_index()\n",
    "    basicStatisticsZoneSizes = shapefile.groupby('cluster').size().describe() # contains\n",
    "    print(f\"Basic statistics of zone aggregation:\\n{basicStatisticsZoneSizes}\\n\")\n",
    "\n",
    "    # Create a new attribute column to store which elements each cluster contains\n",
    "    aggregated[\"elements_1\"] = \"\"\n",
    "    aggregated[\"elements_2\"] = \"\"\n",
    "\n",
    "    # Retrieve which zones are clustered into which cluster\n",
    "    cluster_groups = shapefile.groupby(\"cluster\")\n",
    "    cluster_elements = {}\n",
    "    for cluster_id, group in cluster_groups:\n",
    "        element_ids = group[\"ZONENUMMER\"].tolist()\n",
    "        cluster_elements[cluster_id] = element_ids\n",
    "\n",
    "    # Update the attribute column with the zonenummers for each cluster. Since the attribute columns are limited in size, \n",
    "    # a second column is used if more than 40 zones are clustered into one aggregated zone. \n",
    "    for index, row in aggregated.iterrows():\n",
    "        cluster_id = row[\"cluster\"]\n",
    "        element_ids = cluster_elements.get(cluster_id, [])\n",
    "        if len(element_ids) > 40:\n",
    "            element_ids1 = element_ids[0:40]\n",
    "            element_ids2 = element_ids[40:]\n",
    "            aggregated.at[index, \"elements_1\"] = \", \".join(str(e) for e in element_ids1)\n",
    "            aggregated.at[index, \"elements_2\"] = \", \".join(str(e) for e in element_ids2)\n",
    "        else: \n",
    "            aggregated.at[index, \"elements_1\"] = \", \".join(str(e) for e in element_ids)\n",
    "    \n",
    "    # Save the new shapefile to a file & update the original file\n",
    "    shapefile.to_file(inputFile)\n",
    "    aggregated.to_file(outputFile)\n",
    "\n",
    "    # Return aggregated shapefile\n",
    "    return aggregated\n",
    "\n",
    "agg_shapefile1 = aggregate_zones()\n",
    "agg_shapefile2 = aggregate_zones(radius = radius3, idealNbZonesPerCluster = groupSize3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Update centroids & OD. First we do some processing to make things easier. \n",
    "\n",
    "# After-market fix: add 'cluster' column to unclustered 0-10 radius such that later we have a cluster value for all zones in radius 0-40\n",
    "shapefile0 = gpd.read_file(f'QGIS/{city}_V2_40_10_{radius1}.shp')\n",
    "\n",
    "# no k-nearest neighbour is ran on the smallest radius, but just for naming convention some processing is done \n",
    "shapefile0['cluster'] = range(shapefile0.shape[0])\n",
    "shapefile0['elements_1'] = shapefile0['ZONENUMMER']\n",
    "shapefile0.to_file(f'QGIS/{city}_V2_40_10_{radius1}_knn.shp') \n",
    "\n",
    "# Concatenate shapefiles\n",
    "shapefile1 = gpd.read_file(f'QGIS/{city}_V2_40_10_0-10_knn.shp')\n",
    "shapefile2 = gpd.read_file(f'QGIS/{city}_V2_40_10_{radius2}_knn.shp')\n",
    "shapefile3 = gpd.read_file(f'QGIS/{city}_V2_40_10_{radius3}_knn.shp')\n",
    "\n",
    "# add scalar to cluster numbers before concatenating shapefiles into combined shapefile\n",
    "shapefile2['cluster'] = shapefile2['cluster'] + (shapefile1.cluster.max()+1)\n",
    "shapefile3['cluster'] = shapefile3['cluster'] + (shapefile2.cluster.max()+1)\n",
    "\n",
    "# Save combined shapefile\n",
    "combined_shapefile = gpd.GeoDataFrame(pd.concat([shapefile1, shapefile2, shapefile3]))\n",
    "combined_shapefile.to_file(f'QGIS/{city}_40_10_aggr_comb.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve original OD matrix, original centroids and aggregated shapefile. \n",
    "original_od_matrix = pd.read_excel(\"STA_prep/od_matrix_data/BRUSSEL_40_9_.xlsx\") # TODO define dynamically\n",
    "combined_shapefile = gpd.read_file(f'QGIS/{city}_40_10_aggr_comb.shp')\n",
    "original_shapefile = gpd.read_file(f'QGIS/{city}_V2_40_10.shp')\n",
    "x_centroids = original_shapefile[\"centroid_x\"]\n",
    "y_centroids = original_shapefile[\"centroid_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new OD\n",
    "nbAggZones = len(combined_shapefile)\n",
    "aggregated_od_matrix = np.zeros((nbAggZones, nbAggZones))\n",
    "\n",
    "# Retrieve combined zones of each cluster \n",
    "zones_per_cluster = []\n",
    "for index, row in combined_shapefile.iterrows():\n",
    "    zones_cluster_str = row['elements_1']\n",
    "    zones_cluster = [int(e) for e in zones_cluster_str.split(\",\")]\n",
    "    if len(zones_cluster) >= 40:\n",
    "        zones_cluster_str = row['elements_2']\n",
    "        more_zones = [int(e) for e in zones_cluster_str.split(\",\")]\n",
    "        for zone in more_zones:\n",
    "            zones_cluster.append(zone)\n",
    "    zones_per_cluster.append(zones_cluster) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now new OD and centroids. \n",
    "# Outer loop: fix centroid for every cluster\n",
    "# Inner loop: fix OD for every cluster combination\n",
    "\n",
    "# Outer loop\n",
    "for index_i, row_i in combined_shapefile.iterrows():\n",
    "    # Retrieve all the zones belonging to cluster i    \n",
    "    zones_cluster_i = zones_per_cluster[index_i]\n",
    "\n",
    "    # Calculate cluster centroid: mean of centroids of all the zones in the cluster\n",
    "    centr_x = 0\n",
    "    centr_y = 0\n",
    "    for zone_i in zones_cluster_i:\n",
    "        centr_x += x_centroids[zone_i-1]\n",
    "        centr_y += y_centroids[zone_i-1]\n",
    "    centr_x = centr_x / len(zones_cluster_i)\n",
    "    centr_y = centr_y / len(zones_cluster_i)\n",
    "    combined_shapefile.at[index_i, \"centroid_x\"] = centr_x\n",
    "    combined_shapefile.at[index_i, \"centroid_y\"] = centr_y\n",
    "    \n",
    "    # Inner loop\n",
    "    for index_j, row_j in combined_shapefile.iterrows():\n",
    "        # Retrieve all the zones belonging to cluster j \n",
    "        zones_cluster_j = zones_per_cluster[index_j]\n",
    "        \n",
    "        # Calculate OD flows: sum up the individual flows\n",
    "        aggr_od_flow = 0\n",
    "        for zone_i in zones_cluster_i:\n",
    "            for zone_j in zones_cluster_j:\n",
    "                # VERY IMPORTANT: PANDAS INDEXING SHOULD FIRST SPECIFY COLUMN, AND THEN THE ROW\n",
    "                # Otherwise we are flipping the direction of the summed flows... \n",
    "                aggr_od_flow += original_od_matrix[zone_j-1][zone_i-1]\n",
    "        aggregated_od_matrix[index_i][index_j] = aggr_od_flow\n",
    "\n",
    "# Change to pandas dataframe\n",
    "aggregated_od_matrix = pd.DataFrame(aggregated_od_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new centroids to shapefile\n",
    "combined_shapefile.to_file(f'QGIS/{city}_40_10_aggr_comb.shp')\n",
    "# Save new OD flows to excel\n",
    "aggregated_od_matrix.to_excel(\"QGIS/BRUSSEL_40_9_aggregated.xlsx\", index=False) # Index is False removes the index column (which matches the format of the original OD matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some checks for validity of new OD-matrix. Centroids were manually inspected\n",
    "\n",
    "from_0_10 = [953] # Corresponds to cluster 498 \n",
    "to_0_10 = [705] # Corresponds to cluster 369\n",
    "from_10_20 = [857, 860, 864] # Corresponds to cluster 537\n",
    "to_10_20 = [1029, 1030, 1031, 1095] # Corresponds to cluster 520\n",
    "from_20_40 = [1496, 1572, 1573, 1574, 1602, 1603, 1663] # Corresponds to cluster 623\n",
    "to_20_40 = [999, 1001, 1006, 1007, 1008, 1009, 1089] # Corresponds to cluster 629\n",
    "\n",
    "from_cluster_0_10 = 498\n",
    "from_cluster_10_20 = 537\n",
    "from_cluster_20_40 = 623\n",
    "to_cluster_0_10 = 369\n",
    "to_cluster_10_20 = 520\n",
    "to_cluster_20_40 = 629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998\n",
      "0.998\n"
     ]
    }
   ],
   "source": [
    "# I checked 9 combinations of the above clusters, they were all correct :)\n",
    "sum = 0\n",
    "for i in from_20_40:\n",
    "    for j in to_20_40:\n",
    "        sum += original_od_matrix[j-1][i-1]\n",
    "print(sum)\n",
    "\n",
    "print(aggregated_od_matrix[to_cluster_20_40][from_cluster_20_40])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyntapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
